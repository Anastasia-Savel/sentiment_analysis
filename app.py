import json
import re

import matplotlib.pyplot as plt
import numpy as np
import onnxruntime as ort
import pandas as pd
import seaborn as sns
import streamlit as st
from scipy.special import softmax

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞",
    page_icon="üìà",
)

# –°—Ç–∏–ª–∏ –∫–Ω–æ–ø–æ–∫
st.markdown("""
<style>
    button {
        background: none !important;
        border: none !important;
        box-shadow: none !important;
    }
    button:hover {
        color: #b11226 !important;
        transform: scale(1.02);
    }
    button:active {
        transform: scale(0.98);
    }
    button:focus {
        color: #b11226 !important;
    }
</style>
""", unsafe_allow_html=True)

# –°—Ç–∏–ª–∏ –º–µ—Ç—Ä–∏–∫
st.markdown("""
<style>
    div[data-testid="stMetricValue"] {
        font-size: 20px !important;
    }
    div[data-testid="stMetricLabel"] {
        font-size: 14px !important;
    }
    div[data-testid="stMetricDelta"] {
        font-size: 14px !important;
    }
</style>
""", unsafe_allow_html=True)

# –°—Ç–∏–ª–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–≤
st.markdown("""
<style>
    .stProgress > div > div > div > div {
        background-color: #b11226;
    }
</style>
""", unsafe_allow_html=True)

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ª–æ–≤–∞—Ä—è
@st.cache_resource
def load_vocab(json_path):
    with open(json_path, 'r', encoding='utf-8') as f:
        vocab = json.load(f)
    return vocab

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_onnx_model(onnx_path):
    providers = ['CPUExecutionProvider']
    session = ort.InferenceSession(onnx_path, providers=providers)
    return session

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
def preprocess_text(text, vocab):
    text_lower = text.lower()
    text_cleaned = re.sub(r'[^\w\s]', ' ', text_lower)
    text_cleaned = re.sub(r'\s+', ' ', text_cleaned)
    text_cleaned = re.sub(r'http\S+|www\S+|https\S+', '', text_cleaned)
    text_cleaned = text_cleaned.strip()

    indices = [vocab.get(token, vocab['<unk>']) for token in text_cleaned.split()]

    return np.array(indices, dtype=np.int64).reshape(1, -1)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
def predict_sentiment(text, session, vocab):

    input_data = preprocess_text(text, vocab)

    outputs = session.run(None, {'input': input_data})
    logits = outputs[0][0]

    probabilities = softmax(logits)

    return logits, probabilities


# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–ª–æ–≤–∞—Ä—è
VOCAB_PATH = "word2idx.json"
MODEL_PATH = "lstm_model.onnx"
vocab = load_vocab(VOCAB_PATH)
session = load_onnx_model(MODEL_PATH)
class_names = {0: 'Neutral', 1: 'Positive', 2: 'Negative'}

def set_page(page):
    # –í—ã–±–æ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    st.session_state.page = page

# –õ–µ–≤–æ–µ –º–µ–Ω—é
with st.sidebar:
    st.button("–û –ø—Ä–æ–µ–∫—Ç–µ", on_click=set_page, args=('project',))
    st.button("–î–∞–Ω–Ω—ã–µ", on_click=set_page, args=('data',))
    st.button("–ú–µ—Ç—Ä–∏–∫–∏", on_click=set_page, args=('metrics',))
    st.button("–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫", on_click=set_page, args=('loss',))
    st.button("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LSTM", on_click=set_page, args=('lstm',))
    st.markdown("""
    <style>
    .sidebar-footer {
        position: fixed;
        bottom: 10px;
        left: 10px;
        font-size: 0.8em;
        color: #555555;
    }
    </style>
    <div class="sidebar-footer">
        <p>¬© –ê–Ω–∞—Å—Ç–∞—Å–∏—è –°–∞–≤–µ–ª–æ–≤–∞, 2026 –≥.</p>
    </div>
    """, unsafe_allow_html=True)

if 'text_cleared' not in st.session_state:
    st.session_state.text_cleared = False

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
def clear_text():
    st.session_state.text_area_content = ''

# –°—Ç–∞—Ä—Ç–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
if 'page' not in st.session_state:
    st.session_state.page = 'project'

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü
if st.session_state.page == 'project':
    st.header("–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞")
    st.markdown("#### <span style='color: #b11226'>–û–±–ª–∞—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è:</span>", unsafe_allow_html=True)
    st.markdown("‚Ä¢ –∞–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤ –Ω–∞ —Å–∞–π—Ç–∞—Ö –∏ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞—Ö,\n\n"
             "‚Ä¢ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–π –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö,\n\n"
             "‚Ä¢ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞—â–µ–Ω–∏–π –≤ —Å–ª—É–∂–±—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏,\n\n"
             "‚Ä¢ –æ—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ä–æ—Å–æ–≤ –∏ –∞–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏—è,\n\n"
             "‚Ä¢ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä–µ–ø—É—Ç–∞—Ü–∏–∏ –±—Ä–µ–Ω–¥–∞ –∏ –º–µ–¥–∏–∞-–∞–Ω–∞–ª–∏–∑–∞,\n\n"
             "‚Ä¢ –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–π –≤ –°–ú–ò.")
    st.markdown("#### <span style='color: #b11226'>–ú–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:</span>", unsafe_allow_html=True)
    st.write("‚Ä¢ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏,\n\n"
             "‚Ä¢ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –Ω–∞–∏–≤–Ω–æ–≥–æ –±–∞–π–µ—Å–∞,\n\n"
             "‚Ä¢ —Ä–µ–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å LSTM,\n\n"
             "‚Ä¢ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä SBERT.\n\n")

elif st.session_state.page == 'data':
    st.markdown("#### <span style='color: #b11226'>–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:</span>", unsafe_allow_html=True)
    st.write("–æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å kaggle:\n\nhttps://www.kaggle.com/datasets/mar1mba/russian-sentiment-dataset/data\n\n\n")
    st.markdown("#### <span style='color: #b11226'>–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö:", unsafe_allow_html=True)
    st.write("‚Ä¢ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è,\n\n"
             "‚Ä¢ –æ—á–∏—Å—Ç–∫–∞ –æ—Ç —à—É–º–∞,\n\n"
             "‚Ä¢ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è.\n\n")
    st.write("##### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º")
    st.image('class.png', width=500)
    st.write("##### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ª–æ–≤")
    st.write("\n\n")
    st.image('text.png', use_column_width=True,)

elif st.session_state.page == 'metrics':
    st.markdown("### <span style='color: #b11226'>–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n\n</span>", unsafe_allow_html=True)
    colors = ['#cae1ff', '#fff4ca', '#d2ffd4', '#ffd2ca', '#e8d3ff']

    # F1-score
    data_f1 = {
        '–ú–æ–¥–µ–ª—å': ['Naive Bayes', 'Logistic Regression', 'LSTM + Navec', 'LSTM + Navec (small)', 'SBERT-large'],
        'Neutral': [0.60, 0.60, 0.62, 0.44, 0.59],
        'Positive': [0.78, 0.79, 0.82, 0.5, 0.79],
        'Negative': [0.68, 0.71, 0.73, 0.5, 0.74]
    }

    df_f1 = pd.DataFrame(data_f1)

    df_long = df_f1.melt(id_vars='–ú–æ–¥–µ–ª—å', var_name='–ö–ª–∞—Å—Å', value_name='F1-score')
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.barplot(
        data=df_long,
        x='–ö–ª–∞—Å—Å',
        y='F1-score',
        hue='–ú–æ–¥–µ–ª—å',
        ax=ax,
        palette=colors,
        width=0.7,
        linewidth=1,
        edgecolor='gray'
    )
    ax.spines[['top', 'right']].set_visible(False)
    ax.spines[['left', 'bottom']].set_linewidth(0.7)
    plt.tight_layout()

    st.write("##### F1-score\n\n</span>", unsafe_allow_html=True)
    st.dataframe(df_f1.set_index('–ú–æ–¥–µ–ª—å'), use_container_width=True)
    st.pyplot(fig)

    #Accuracy + Time
    data_acc_tm = {
        '–ú–æ–¥–µ–ª—å': ['Naive Bayes', 'Logistic Regression', 'LSTM + Navec', 'LSTM + Navec (small)', 'SBERT-large'],
        'Accuracy': [0.68, 0.70, 0.72, 0.48, 0.71],
        'Time (sec)': [0.017, 0.037, 0.032, 0.002, 0.015],
    }
    df_acc_tm = pd.DataFrame(data_acc_tm)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))

    # –ì—Ä–∞—Ñ–∏–∫ Accuracy
    sns.barplot(
        data=df_acc_tm,
        x='–ú–æ–¥–µ–ª—å',
        y='Accuracy',
        ax=ax1,
        palette=colors,
        width=0.5,
        linewidth=1,
        edgecolor='gray'
    )
    ax1.set_ylabel('Accuracy', fontsize=12)
    ax1.set_xlabel('')
    ax1.set_xticklabels([])
    ax1.set_xticks([])
    ax1.set_ylim(0, 1)

    # –ì—Ä–∞—Ñ–∏–∫ Time
    sns.barplot(
        data=df_acc_tm,
        x='–ú–æ–¥–µ–ª—å',
        y='Time (sec)',
        ax=ax2,
        palette=colors,
        width=0.5,
        linewidth=1,
        edgecolor='gray'
    )
    ax2.set_ylabel('Time (sec)', fontsize=12)
    ax2.set_xlabel('')
    ax2.set_xticklabels([])
    ax2.set_xticks([])

    for ax in [ax1, ax2]:
        ax.spines[['top', 'right']].set_visible(False)
        ax.spines[['left', 'bottom']].set_linewidth(0.7)
    handles = [plt.Rectangle((0, 0), 1, 1, color=colors[i], edgecolor='gray')
               for i in range(len(df_acc_tm['–ú–æ–¥–µ–ª—å']))]
    fig.legend(handles, df_acc_tm['–ú–æ–¥–µ–ª—å'],
               title='–ú–æ–¥–µ–ª—å',
               loc='center right',
               bbox_to_anchor=(0.3, 0.85),
               fontsize=11,
               title_fontsize=12)
    plt.tight_layout()

    st.write("##### Accuracy + Time\n\n</span>", unsafe_allow_html=True)
    st.dataframe(df_acc_tm.set_index('–ú–æ–¥–µ–ª—å'), use_container_width=True)
    st.pyplot(fig)


elif st.session_state.page == 'loss':
    st.markdown("### <span style='color: #b11226'>–ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫\n\n</span>", unsafe_allow_html=True)
    st.write("##### –ù–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å")
    st.image('confusion_matrix_nb.png', width=500)
    st.write("##### –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è")
    st.image('confusion_matrix_lr.png', width=500)
    st.write("##### LSTM + NAVEC")
    st.image('confusion_matrix_lstm.png', width=500)
    st.write("##### LSTM + NAVEC (small)")
    st.image('confusion_matrix_lstm_quant.png', width=500)
    st.write("##### SBERT-large")
    st.image('confusion_matrix_sbert.png', width=500)

elif st.session_state.page == 'lstm':
    st.markdown("#### <span style='color: #b11226'>–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LSTM</span>", unsafe_allow_html=True)

    text_input = st.text_area(
        "",
        height=150,
        placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏",
        key="text_area_content",
        value="" if st.session_state.get('text_cleared', False) else st.session_state.get('text_area_content', '')
    )

    col1, col2 = st.columns([1, 1])

    # –°–±—Ä–æ—Å —Ñ–ª–∞–≥–∞ –æ—á–∏—Å—Ç–∫–∏
    if st.session_state.text_cleared:
        st.session_state.text_cleared = False

    with col1:
        analyze_clicked = st.button("üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", use_container_width=True)

    with col2:
        st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", use_container_width=True, on_click=clear_text)

    if analyze_clicked and text_input.strip():
        with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç..."):
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            logits, probs = predict_sentiment(text_input, session, vocab)
            predicted_class = np.argmax(probs).item()

            class_names = ["–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π", "–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π", "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π"]
            class_icons = ["‚óØ", "‚úî", "‚úò"]
            class_colors = ["#808080", "#4CAF50", "#F44336"]

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.divider()
            col_result1, col_result2, col_result3 = st.columns(3)
            with col_result1:
                st.metric(
                    label="–ö–ª–∞—Å—Å",
                    value=f"{class_icons[predicted_class]} {class_names[predicted_class]}",
                )

            with col_result2:
                st.metric(
                    label="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏",
                    value=f"{probs[predicted_class] * 100:.1f}%"
                )
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            st.write("##### –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤:\n\n")
            cols = st.columns(3)
            for i in range(3):
                with cols[i]:
                    st.progress(float(probs[i]), text=f"{class_names[i]}")
                    st.markdown(f"""
                    <div style='text-align: center'>
                        <h3 style='color: {class_colors[i]}'>{class_icons[i]}</h3>
                        <p><b>{probs[i] * 100:.2f}%</b></p>
                    </div>
                    """, unsafe_allow_html=True)

    if analyze_clicked and not text_input.strip():
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

